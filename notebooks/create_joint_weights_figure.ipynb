{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to decode which feature was selected per-trial based on firing rates of neurons\n",
    "# experiment with ranges of firing rates around fixation (selection) time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "import utils.io_utils as io_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "from models.value_models import ValueLinearModel, ValueNormedModel\n",
    "from models.multinomial_logistic_regressor import MultinomialLogisticRegressor, NormedMultinomialLogisticRegressor\n",
    "from models.model_wrapper import ModelWrapper\n",
    "\n",
    "from models.trainer import Trainer\n",
    "\n",
    "import torch\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. \n",
    "\n",
    "feature_dims = [\"Color\", \"Shape\", \"Pattern\"]\n",
    "\n",
    "pre_interval = 1300\n",
    "post_interval = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "fs = s3fs.S3FileSystem()\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\", \"Incorrect\"])]   \n",
    "shuffled_card_idxs = behavioral_utils.get_shuffled_card_idxs(valid_beh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find clusters of units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/src/wcst_decode/notebooks/create_joint_weights_figure.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3132382e39352e38312e3439227d7d/src/wcst_decode/notebooks/create_joint_weights_figure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m models \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(fs\u001b[39m.\u001b[39;49mopen(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39ml2l.pqz317.scratch/value_normed_model_models_\u001b[39;49m\u001b[39m{\u001b[39;49;00mpre_interval\u001b[39m}\u001b[39;49;00m\u001b[39m_fb_\u001b[39;49m\u001b[39m{\u001b[39;49;00mpost_interval\u001b[39m}\u001b[39;49;00m\u001b[39m_by_bin_random_split.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m), allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3132382e39352e38312e3439227d7d/src/wcst_decode/notebooks/create_joint_weights_figure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m weights \u001b[39m=\u001b[39m classifier_utils\u001b[39m.\u001b[39mevaluate_model_weights_by_time_bins(models, \u001b[39m59\u001b[39m, \u001b[39m12\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:413\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode)\n\u001b[1;32m    412\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    414\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs)\n\u001b[1;32m    415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py:746\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m     pickle_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    745\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     array \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(fp, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_kwargs)\n\u001b[1;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    748\u001b[0m     \u001b[39m# Friendlier error message\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mUnicodeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnpickling a python object failed: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    750\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mYou may need to pass the encoding= option \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mto numpy.load\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (err,)) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/storage.py:218\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(io\u001b[39m.\u001b[39;49mBytesIO(b))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:930\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    928\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    929\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m--> 930\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    932\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    934\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:876\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    872\u001b[0m     obj\u001b[39m.\u001b[39m_torch_load_uninitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    873\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     \u001b[39m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     deserialized_objects[root_key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[0;32m--> 876\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(obj, location),\n\u001b[1;32m    877\u001b[0m         dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    879\u001b[0m typed_storage \u001b[39m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    880\u001b[0m \u001b[39mif\u001b[39;00m view_metadata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    176\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    153\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "models = np.load(fs.open(f\"l2l.pqz317.scratch/value_normed_model_models_{pre_interval}_fb_{post_interval}_by_bin_random_split.npy\"), allow_pickle=True)\n",
    "weights = classifier_utils.evaluate_model_weights_by_time_bins(models, 59, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
