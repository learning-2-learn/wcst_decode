{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode Features of Card Selections with Spiking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to decode which feature was selected per-trial based on firing rates of neurons\n",
    "# experiment with ranges of firing rates around fixation (selection) time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from sklearn import svm\n",
    "\n",
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. \n",
    "pre_interval = 1300\n",
    "post_interval = 1500\n",
    "\n",
    "feature_dims = [\"Color\", \"Shape\", \"Pattern\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data from S3, FileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "fs = s3fs.S3FileSystem()\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\", \"Incorrect\"])]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selections = pd.read_pickle(fs.open(\"l2l.pqz317.scratch/feature_selections.pickle\"))\n",
    "firing_rates = pd.read_pickle(fs.open(f\"l2l.pqz317.scratch/firing_rates_{pre_interval}_fb_{post_interval}.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fig_by_splitter(feature_dim, splitter, splitter_name, clf_type, clf, inputs, labels):\n",
    "    test_accs_by_bin, shuffled_accs, _, _ = classifier_utils.evaluate_classifiers_by_time_bins(\n",
    "        clf, inputs, labels, np.arange(0, 2.8, 0.1), splitter\n",
    "    )\n",
    "    np.save(fs.open(f\"l2l.pqz317.scratch/{feature_dim}_{clf_type}_accs_{pre_interval}_fb_{post_interval}_by_bin_{splitter_name}_split.npy\", \"wb\"), test_accs_by_bin)\n",
    "    np.save(fs.open(f\"l2l.pqz317.scratch/{feature_dim}_{clf_type}_shuffled_accs_{pre_interval}_fb_{post_interval}_by_bin_{splitter_name}_split.npy\", \"wb\"), shuffled_accs)\n",
    "\n",
    "    # # generate figures\n",
    "    fig, ax = plt.subplots()\n",
    "    visualization_utils.visualize_accuracy_across_time_bins(\n",
    "        test_accs_by_bin,\n",
    "        pre_interval, post_interval, 100,\n",
    "        ax,\n",
    "    )\n",
    "    visualization_utils.visualize_accuracy_across_time_bins(\n",
    "        shuffled_accs,\n",
    "        pre_interval, post_interval, 100,\n",
    "        ax,\n",
    "    )\n",
    "    ax.axvline(-800, color='k')\n",
    "    ax.set_xlabel(\"Time Bins (ms)\")\n",
    "    ax.set_ylabel(\"Decoder Accuracy\")\n",
    "    ax.set_title(f\"Decoding {feature_dim} with 100ms Bins of Spiking\")\n",
    "    plt.savefig(f\"../data/{clf_type}_accs_{splitter_name}_split_{feature_dim}_{pre_interval}_fb_{post_interval}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dim Color\n",
      "Generating figs for Random Splitter\n",
      "Evaluating for bin 0.0\n",
      "Evaluating for bin 0.1\n",
      "Evaluating for bin 0.2\n",
      "Evaluating for bin 0.30000000000000004\n",
      "Evaluating for bin 0.4\n",
      "Evaluating for bin 0.5\n",
      "Evaluating for bin 0.6000000000000001\n",
      "Evaluating for bin 0.7000000000000001\n",
      "Evaluating for bin 0.8\n",
      "Evaluating for bin 0.9\n",
      "Evaluating for bin 1.0\n",
      "Evaluating for bin 1.1\n",
      "Evaluating for bin 1.2000000000000002\n",
      "Evaluating for bin 1.3\n",
      "Evaluating for bin 1.4000000000000001\n",
      "Evaluating for bin 1.5\n",
      "Evaluating for bin 1.6\n",
      "Evaluating for bin 1.7000000000000002\n",
      "Evaluating for bin 1.8\n",
      "Evaluating for bin 1.9000000000000001\n",
      "Evaluating for bin 2.0\n",
      "Evaluating for bin 2.1\n",
      "Evaluating for bin 2.2\n",
      "Evaluating for bin 2.3000000000000003\n",
      "Evaluating for bin 2.4000000000000004\n",
      "Evaluating for bin 2.5\n",
      "Evaluating for bin 2.6\n",
      "Evaluating for bin 2.7\n",
      "Feature dim Shape\n",
      "Generating figs for Random Splitter\n",
      "Evaluating for bin 0.0\n",
      "Evaluating for bin 0.1\n",
      "Evaluating for bin 0.2\n",
      "Evaluating for bin 0.30000000000000004\n",
      "Evaluating for bin 0.4\n",
      "Evaluating for bin 0.5\n",
      "Evaluating for bin 0.6000000000000001\n",
      "Evaluating for bin 0.7000000000000001\n",
      "Evaluating for bin 0.8\n",
      "Evaluating for bin 0.9\n",
      "Evaluating for bin 1.0\n",
      "Evaluating for bin 1.1\n",
      "Evaluating for bin 1.2000000000000002\n",
      "Evaluating for bin 1.3\n",
      "Evaluating for bin 1.4000000000000001\n",
      "Evaluating for bin 1.5\n",
      "Evaluating for bin 1.6\n",
      "Evaluating for bin 1.7000000000000002\n",
      "Evaluating for bin 1.8\n",
      "Evaluating for bin 1.9000000000000001\n",
      "Evaluating for bin 2.0\n",
      "Evaluating for bin 2.1\n",
      "Evaluating for bin 2.2\n",
      "Evaluating for bin 2.3000000000000003\n",
      "Evaluating for bin 2.4000000000000004\n",
      "Evaluating for bin 2.5\n",
      "Evaluating for bin 2.6\n",
      "Evaluating for bin 2.7\n",
      "Feature dim Pattern\n",
      "Generating figs for Random Splitter\n",
      "Evaluating for bin 0.0\n",
      "Evaluating for bin 0.1\n",
      "Evaluating for bin 0.2\n",
      "Evaluating for bin 0.30000000000000004\n",
      "Evaluating for bin 0.4\n",
      "Evaluating for bin 0.5\n",
      "Evaluating for bin 0.6000000000000001\n",
      "Evaluating for bin 0.7000000000000001\n",
      "Evaluating for bin 0.8\n",
      "Evaluating for bin 0.9\n",
      "Evaluating for bin 1.0\n",
      "Evaluating for bin 1.1\n",
      "Evaluating for bin 1.2000000000000002\n",
      "Evaluating for bin 1.3\n",
      "Evaluating for bin 1.4000000000000001\n",
      "Evaluating for bin 1.5\n",
      "Evaluating for bin 1.6\n",
      "Evaluating for bin 1.7000000000000002\n",
      "Evaluating for bin 1.8\n",
      "Evaluating for bin 1.9000000000000001\n",
      "Evaluating for bin 2.0\n",
      "Evaluating for bin 2.1\n",
      "Evaluating for bin 2.2\n",
      "Evaluating for bin 2.3000000000000003\n",
      "Evaluating for bin 2.4000000000000004\n",
      "Evaluating for bin 2.5\n",
      "Evaluating for bin 2.6\n",
      "Evaluating for bin 2.7\n"
     ]
    }
   ],
   "source": [
    "for feature_dim in feature_dims:\n",
    "    print(f\"Feature dim {feature_dim}\")\n",
    "    clf = svm.SVC(decision_function_shape='ovo')\n",
    "    # Look at Spike Counts instead of Firing Rate\n",
    "    mode = \"SpikeCounts\"\n",
    "\n",
    "    # prep data for classification\n",
    "    inputs = firing_rates.rename(columns={mode: \"Value\"})\n",
    "    labels = feature_selections.rename(columns={feature_dim: \"Feature\"})\n",
    "\n",
    "    print(f\"Generating figs for Random Splitter\")\n",
    "    random_splitter = RandomSplitter(labels.TrialNumber.unique(), 20, 0.2)\n",
    "    create_fig_by_splitter(feature_dim, random_splitter, \"random\", \"svm\", clf, inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "visualization_utils.plot_dist_of_selections(feature_selections, \"Color\", ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
