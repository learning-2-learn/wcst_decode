{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to decode which feature was selected per-trial based on firing rates of neurons\n",
    "# experiment with ranges of firing rates around fixation (selection) time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from sklearn import svm\n",
    "\n",
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\", \"Incorrect\"])]\n",
    "trial_numbers = np.unique(valid_beh.TrialNumber)\n",
    "spike_data = spike_general.get_spike_times_by_trial(fs, subject, session, trial=trial_numbers, start_field=\"TrialStart\", end_field=\"TrialEnd\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find \"fixation times\". In this case, 800ms before feedback. \n",
    "pre_interval = 800\n",
    "post_interval = 0\n",
    "intervals = behavioral_utils.get_trial_intervals(valid_beh, \"FeedbackOnset\", pre_interval, post_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the spikes falling in the intervals\n",
    "spike_times = spike_general.get_spike_times(fs, subject, session)\n",
    "spike_by_trial_interval = spike_utils.get_spikes_by_trial_interval(spike_times, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab firing rates, spike counts, in 800ms intervals, 100ms bins\n",
    "firing_rates = spike_analysis.firing_rate(spike_by_trial_interval, bins=np.arange(0, 0.9, 0.1), smoothing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab Shape, Color, Pattern features for each selection\n",
    "selections = behavioral_utils.get_selection_features(valid_beh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load what's already been computed\n",
    "feature_selections = pd.read_pickle(\"../data/feature_selections.pickle\")\n",
    "firing_rates = pd.read_pickle(\"../data/firing_rates.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a support vector machine model\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Look at Spike Counts instead of Firing Rate\n",
    "mode = \"SpikeCounts\"\n",
    "\n",
    "# Look at 'Pattern' as a dimension\n",
    "feature_dim = \"Pattern\"\n",
    "\n",
    "# prep data for classification\n",
    "inputs = firing_rates.rename(columns={mode: \"Value\"})\n",
    "labels = feature_selections.rename(columns={feature_dim: \"Feature\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly grab trials for train/test, run 20 times, split 80/20\n",
    "random_splitter = RandomSplitter(labels.TrialNumber.unique(), 20, 0.2)\n",
    "train_accs, test_accs, shuffled_accs, models = classifier_utils.evaluate_classifier(clf, inputs, labels, random_splitter)\n",
    "print(f\"Mean Train accuracy: {np.mean(train_accs)}, Test accuracy: {np.mean(test_accs)}, Shuffled accuracy: {np.mean(shuffled_accs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split trials into train/test by blocks, always leave one block out for test. \n",
    "block_splitter = BlockSplitter(valid_beh)\n",
    "train_accs, test_accs, shuffled_accs, models = classifier_utils.evaluate_classifier(clf, inputs, labels, block_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look across different time bins, evaluate classifier on each time bin individually\n",
    "time_bins = np.arange(0.0, 0.8, 0.1)\n",
    "for bin in time_bins:\n",
    "    inputs_for_bin = inputs[inputs[\"TimeBins\"] == bin]\n",
    "    train_accs, test_accs, shuffled_accs, models = classifier_utils.evaluate_classifier(clf, inputs_for_bin, labels, random_splitter)\n",
    "    print(f\"Mean Train accuracy: {np.mean(train_accs)}, Test accuracy: {np.mean(test_accs)}, Shuffled accuracy: {np.mean(shuffled_accs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
