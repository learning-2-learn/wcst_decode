{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Try to decode which feature was selected per-trial based on firing rates of neurons\n",
    "# experiment with ranges of firing rates around fixation (selection) time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from sklearn import svm\n",
    "\n",
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\", \"Incorrect\"])]\n",
    "trial_numbers = np.unique(valid_beh.TrialNumber)\n",
    "spike_times = spike_general.get_spike_times(fs, subject, session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  9 10 11 12 13 15 17 18 19 35 39 42 43 44 45 46 47\n",
      " 48 49 54 55 59]\n",
      "[ 8 14 16 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 36 37 38 40 41 50\n",
      " 51 52 53 56 57 58]\n"
     ]
    }
   ],
   "source": [
    "spike_general.list_session_units(fs, subject, session)\n",
    "\n",
    "temp_units = spike_utils.get_temporal_drive_unit_ids(fs, subject, session)\n",
    "print(temp_units)\n",
    "\n",
    "ant_units = spike_utils.get_anterior_drive_unit_ids(fs, subject, session)\n",
    "print(ant_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find \"fixation times\". In this case, 800ms before feedback. \n",
    "pre_interval = 800\n",
    "post_interval = 0\n",
    "intervals = behavioral_utils.get_trial_intervals(valid_beh, \"FeedbackOnset\", pre_interval, post_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the spikes falling in the intervals\n",
    "spike_times = spike_general.get_spike_times(fs, subject, session)\n",
    "spike_by_trial_interval = spike_utils.get_spikes_by_trial_interval(spike_times, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab firing rates, spike counts, in 800ms intervals, 100ms bins\n",
    "firing_rates = spike_analysis.firing_rate(spike_by_trial_interval, bins=np.arange(0, 0.9, 0.1), smoothing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab Shape, Color, Pattern features for each selection\n",
    "selections = behavioral_utils.get_selection_features(valid_beh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections.to_pickle(fs.open(f\"l2l.pqz317.scratch/feature_selections.pickle\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/feature_selections.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/src/wcst_decode/notebooks/decode_feature_selected.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3132382e39352e38312e3439227d7d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load what's already been computed\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3132382e39352e38312e3439227d7d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m feature_selections \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39m\"\u001b[39;49m\u001b[39m../data/feature_selections.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3132382e39352e38312e3439227d7d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m firing_rates \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m\"\u001b[39m\u001b[39m../data/firing_rates.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/pickle.py:187\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m    186\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 187\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    188\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    189\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    190\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    191\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    192\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    193\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    201\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:795\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    796\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    798\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/feature_selections.pickle'"
     ]
    }
   ],
   "source": [
    "# load what's already been computed\n",
    "feature_selections = pd.read_pickle(\"../data/feature_selections.pickle\")\n",
    "firing_rates = pd.read_pickle(\"../data/firing_rates.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a support vector machine model\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Look at Spike Counts instead of Firing Rate\n",
    "mode = \"SpikeCounts\"\n",
    "\n",
    "# Look at 'Pattern' as a dimension\n",
    "feature_dim = \"Pattern\"\n",
    "\n",
    "# prep data for classification\n",
    "inputs = firing_rates.rename(columns={mode: \"Value\"})\n",
    "labels = feature_selections.rename(columns={feature_dim: \"Feature\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly grab trials for train/test, run 20 times, split 80/20\n",
    "random_splitter = RandomSplitter(labels.TrialNumber.unique(), 20, 0.2)\n",
    "train_accs, test_accs, shuffled_accs, models = classifier_utils.evaluate_classifier(clf, inputs, labels, random_splitter)\n",
    "print(f\"Mean Train accuracy: {np.mean(train_accs)}, Test accuracy: {np.mean(test_accs)}, Shuffled accuracy: {np.mean(shuffled_accs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split trials into train/test by blocks, always leave one block out for test. \n",
    "block_splitter = BlockSplitter(valid_beh)\n",
    "train_accs, test_accs, shuffled_accs, models = classifier_utils.evaluate_classifier(clf, inputs, labels, block_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look across different time bins, evaluate classifier on each time bin individually\n",
    "time_bins = np.arange(0.0, 0.8, 0.1)\n",
    "for bin in time_bins:\n",
    "    inputs_for_bin = inputs[inputs[\"TimeBins\"] == bin]\n",
    "    train_accs, test_accs, shuffled_accs, models = classifier_utils.evaluate_classifier(clf, inputs_for_bin, labels, random_splitter)\n",
    "    print(f\"Mean Train accuracy: {np.mean(train_accs)}, Test accuracy: {np.mean(test_accs)}, Shuffled accuracy: {np.mean(shuffled_accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find \"fixation times\". In this case, 800ms before feedback. \n",
    "pre_interval = 1200\n",
    "post_interval = 800\n",
    "intervals = behavioral_utils.get_trial_intervals(valid_beh, \"FeedbackOnset\", pre_interval, post_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the spikes falling in the intervals\n",
    "spike_times = spike_general.get_spike_times(fs, subject, session)\n",
    "spike_by_trial_interval = spike_utils.get_spikes_by_trial_interval(spike_times, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_by_trial_interval.to_pickle(\"../data/spike_by_trial_interval_1200_fb_800.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_by_trial_interval = pd.read_pickle(\"../data/spike_by_trial_interval_1200_fb_800.pickle\")\n",
    "firing_rates = spike_analysis.firing_rate(spike_by_trial_interval, bins=np.arange(0, 2.1, 0.1), smoothing=1)\n",
    "firing_rates.to_pickle(\"../data/firing_rates_1200_fb_800.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selections = pd.read_pickle(\"../data/feature_selections.pickle\")\n",
    "firing_rates = pd.read_pickle(\"../data/firing_rates_1200_fb_800.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a support vector machine model\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Look at Spike Counts instead of Firing Rate\n",
    "mode = \"SpikeCounts\"\n",
    "\n",
    "# Look at 'Pattern' as a dimension\n",
    "feature_dim = \"Pattern\"\n",
    "\n",
    "# prep data for classification\n",
    "inputs = firing_rates.rename(columns={mode: \"Value\"})\n",
    "labels = feature_selections.rename(columns={feature_dim: \"Feature\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by SVC.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/src/wcst_decode/notebooks/decode_feature_selected.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=0'>1</a>\u001b[0m random_splitter \u001b[39m=\u001b[39m RandomSplitter(labels\u001b[39m.\u001b[39mTrialNumber\u001b[39m.\u001b[39munique(), \u001b[39m20\u001b[39m, \u001b[39m0.2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=1'>2</a>\u001b[0m ant_inputs \u001b[39m=\u001b[39m inputs[inputs[\u001b[39m\"\u001b[39m\u001b[39mUnitID\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misin(ant_units)]\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=2'>3</a>\u001b[0m test_accs_by_bin, shuffled_accs \u001b[39m=\u001b[39m classifier_utils\u001b[39m.\u001b[39;49mevaluate_classifiers_by_time_bins(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=3'>4</a>\u001b[0m     clf, ant_inputs, labels, np\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, \u001b[39m2.8\u001b[39;49m, \u001b[39m0.1\u001b[39;49m), random_splitter\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=6'>7</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=7'>8</a>\u001b[0m visualization_utils\u001b[39m.\u001b[39mvisualize_accuracy_across_time_bins(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=8'>9</a>\u001b[0m     test_accs_by_bin,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39m1200\u001b[39m, \u001b[39m800\u001b[39m, \u001b[39m100\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=10'>11</a>\u001b[0m     ax,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=11'>12</a>\u001b[0m     label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAnterior Units\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776373745f6465636f64652d6e6f7465626f6f6b2d31227d/src/wcst_decode/notebooks/decode_feature_selected.ipynb#ch0000019vscode-remote?line=12'>13</a>\u001b[0m )\n",
      "File \u001b[0;32m/src/wcst_decode/utils/classifier_utils.py:93\u001b[0m, in \u001b[0;36mevaluate_classifiers_by_time_bins\u001b[0;34m(clf, inputs, labels, time_bins, splitter)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m i, \u001b[39mbin\u001b[39m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(time_bins):\n\u001b[1;32m     91\u001b[0m     \u001b[39m# need isclose because the floats get stored weird\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     inputs_for_bin \u001b[39m=\u001b[39m inputs[np\u001b[39m.\u001b[39misclose(inputs[\u001b[39m\"\u001b[39m\u001b[39mTimeBins\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mbin\u001b[39m)]\n\u001b[0;32m---> 93\u001b[0m     train_accs, test_accs, shuffled_accs, models \u001b[39m=\u001b[39m evaluate_classifier(\n\u001b[1;32m     94\u001b[0m         clf, inputs_for_bin, labels, splitter\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m     test_accs_by_bin[i, :] \u001b[39m=\u001b[39m test_accs\n\u001b[1;32m     97\u001b[0m     shuffled_accs_by_bin[i, :] \u001b[39m=\u001b[39m shuffled_accs\n",
      "File \u001b[0;32m/src/wcst_decode/utils/classifier_utils.py:70\u001b[0m, in \u001b[0;36mevaluate_classifier\u001b[0;34m(clf, firing_rates, feature_selections, trial_splitter)\u001b[0m\n\u001b[1;32m     68\u001b[0m X_test \u001b[39m=\u001b[39m transform_to_input_data(firing_rates, trials_filter\u001b[39m=\u001b[39mtest_trials)\n\u001b[1;32m     69\u001b[0m y_test \u001b[39m=\u001b[39m transform_to_label_data(feature_selections, trials_filter\u001b[39m=\u001b[39mtest_trials)\n\u001b[0;32m---> 70\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     72\u001b[0m train_acc \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mscore(X_train, y_train)\n\u001b[1;32m     73\u001b[0m test_acc \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    174\u001b[0m         X,\n\u001b[1;32m    175\u001b[0m         y,\n\u001b[1;32m    176\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    177\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    178\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    179\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    182\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    184\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[1;32m    185\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    186\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 909\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    910\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    915\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    916\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by SVC."
     ]
    }
   ],
   "source": [
    "random_splitter = RandomSplitter(labels.TrialNumber.unique(), 20, 0.2)\n",
    "ant_inputs = inputs[inputs[\"UnitID\"].isin(ant_units)]\n",
    "_, test_accs_by_bin, shuffled_accs, _, _ = classifier_utils.evaluate_classifiers_by_time_bins(\n",
    "    clf, ant_inputs, labels, np.arange(0, 2, 0.1), random_splitter\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "visualization_utils.visualize_accuracy_across_time_bins(\n",
    "    test_accs_by_bin,\n",
    "    1200, 800, 100,\n",
    "    ax,\n",
    "    label=\"Anterior Units\"\n",
    ")\n",
    "visualization_utils.visualize_accuracy_across_time_bins(\n",
    "    shuffled_accs,\n",
    "    1200, 800, 100,\n",
    "    ax,\n",
    "    label=\"Shuffled\"\n",
    ")\n",
    "\n",
    "temp_inputs = inputs[inputs[\"UnitID\"].isin(temp_units)]\n",
    "test_accs_by_bin, shuffled_accs, _, _ = classifier_utils.evaluate_classifiers_by_time_bins(\n",
    "    clf, temp_inputs, labels, np.arange(0, 2.8, 0.1), random_splitter\n",
    ")\n",
    "\n",
    "visualization_utils.visualize_accuracy_across_time_bins(\n",
    "    shuffled_accs,\n",
    "    1200, 800, 100,\n",
    "    ax,\n",
    "    label=\"Temporal Units\"\n",
    ")\n",
    "ax.legend()\n",
    "ax.axvline(-800, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/accs_by_bin_block_splitter.npy\", test_accs_by_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
