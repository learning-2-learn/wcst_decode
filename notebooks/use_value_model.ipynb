{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Try to decode which feature was selected per-trial based on firing rates of neurons\n",
    "# experiment with ranges of firing rates around fixation (selection) time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "import utils.io_utils as io_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "from models.value_model import ValueModel\n",
    "\n",
    "from models.trainer import Trainer\n",
    "\n",
    "import torch\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 150\n",
    "\n",
    "\n",
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. \n",
    "pre_interval = 1300\n",
    "post_interval = 1500\n",
    "\n",
    "feature_dims = [\"Color\", \"Shape\", \"Pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "fs = s3fs.S3FileSystem()\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\", \"Incorrect\"])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selections = pd.read_pickle(fs.open(\"l2l.pqz317.scratch/feature_selections.pickle\"))\n",
    "firing_rates = pd.read_pickle(fs.open(\"l2l.pqz317.scratch/firing_rates_1300_fb_1500_100_bins.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['CIRCLE', 'SQUARE', 'STAR', 'TRIANGLE', 'CYAN', 'GREEN', 'MAGENTA', 'YELLOW', 'ESCHER', 'POLKADOT', 'RIPPLE', 'SWIRL']\n",
    "cards = np.empty((len(valid_beh), 4, 3))\n",
    "\n",
    "for card_idx in range(4):\n",
    "    for dim_idx, dim in enumerate([\"Color\", \"Shape\", \"Pattern\"]):\n",
    "        features = valid_beh[f\"Item{card_idx}{dim}\"]\n",
    "        features_idx = features.apply(lambda f: FEATURES.index(f))\n",
    "        cards[:, card_idx, dim_idx] = features_idx\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to play around with value model, see if it works:\n",
    "inputs_for_bin = firing_rates[np.isclose(firing_rates[\"TimeBins\"], 0.1)]\n",
    "renamed = inputs_for_bin.rename(columns={\"SpikeCounts\": \"Value\"})\n",
    "model_inputs = classifier_utils.transform_to_input_data(renamed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ValueModel(59, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1749, 12])\n",
      "torch.Size([1749, 4])\n"
     ]
    }
   ],
   "source": [
    "res = model(torch.Tensor(model_inputs), cards)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
